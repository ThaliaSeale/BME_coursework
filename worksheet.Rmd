---
title: "Biostatistics"
output:
  html_document:
    df_print: paged
---

# Basics of R Operations

## Basic operations

```{r}
15 + 97
```

Assignment operator:

```{r}
x <- 15
x + 97 -> y # a right arrow also works! 
```

`=` also works for assignment:

```{r}
x = 25
```

## Vectors

Pointwise operations:

```{r}
x <- c(1,-1,3,5,2) # creating a vector
x + 2
x^2
(x - 2)^2
```

Sometimes, we need to repeat...

```{r}
rep(5,3)
rep(2:5, each = 3)
rep(-3:2, length.out = 12)
```

Sequences:

```{r}
1:10
-3:4
9:5
```

For generalisation:

```{r}
seq(from = 2, to = 6, by = 0.4)
seq(-1, 1, length = 6)
```

## Recycling

If we apply binary operation on two vectors of different lengths, the smaller one is used repeatedly until the end of larger one:

```{r}
2^(0:10)
1:10 * c(-1,1)
1:3 + rep(seq(from = 0, by = 10, to = 30), each = 3)
```
What happens when the vectors are the same length?

### EXERCISE 1

(i) 1, 1.5, 2, 2.5, ... , 12

```{r}
# ANSWER HERE
```

(ii) 1, 8, 27, 64, ..., 1000

```{r}
# ANSWER HERE
```

(iii) 1, -1/2, 1/3, -1/4, ... , -1/100

```{r}
# ANSWER HERE
```

(iv) 1, 0, 3, 0, 5, ... , 0, 49

```{r}
# ANSWER HERE
```

(v) 1, 3, 6, 10, 15, ... , 210

```{r}
# ANSWER HERE
```

(v) 1, 2, 2, 3, 3, 3, ... , 10

```{r}
# ANSWER HERE
```

EXTENSION: In the Taylor series expansion of $\log(1 + x)$, the $i$th term is $\frac{(-1)^{i+1} x^i}{i}$. Create a vector containing the first 100 entries of the series for $x = 0.5$

```{r}
# ANSWER HERE
```

## Elements of vectors

```{r}
x <- c(5, 10, 45, 32, 11, 17, 99, 46, 32)

x[3]
x[c(1, 6, 3)]
x[1:3]
x[3:length(x)]
```
Removing entries:

```{r}
x[-1]
x[-c(1,4)]
```

## Logical Operations

Logical operations are vectorised:

```{r}
x >= 50
x < 40
x == 45
x != 99
```

```{r}
(x > 10) & (x < 40)  # AND
(x == 10) | (x > 40) # OR
!(x > 40)            # NOT
```
```{r}
x[(x == 5) | (x > 40)]
```

```{r}
LETTERS[!LETTERS %in% c("A", "E", "I", "O", "U")]
```

## Character vectors

```{r}
S <- c("Apple", "Ball", "Call", 4000)
S
```

What happens to the type of 4000?

```{r}
S[1:2]
S[-c(1,3)]
c(S[1:3], 'Dog')
```

etc.

# Basics of Descriptive Statistics and Data Visualisation

First let's load some data...

```{r}
data('cars')
```



Have a look through the dataset:

```{r}
cars
```

## Standard plots in R

### EXERCISE 2

(i) Generate a histogram for the speed:

```{r}
?hist # you can run this to view the documentation for hist on the help panel

# ANSWER HERE
```

(ii) Generate a histogram of the distance. Change the bins to be width 10 and the fill colour to green.

```{r}
# ANSWER HERE
```

(iii) Generate a point plot of speed against distance.

```{r}
?plot
```

## Better graphs...

You can download new packages from CRAN that expands the functionality of R:

```{r}
install.packages('ggplot2') # install the package
library(ggplot2) # load the package
```

Example using ggplot:

```{r}
ggplot(cars, aes(x = speed)) +
  geom_histogram(color = "black", fill = "white")
```

### EXERCISE 3

What is `aes` doing?

(i) Change the above plot to a horizontal bar plot.
(ii) Create different colour bars for men and women.

```{r}
?geom_histogram
```

## Measures of Central Tendency

```{r}
mean(cars$dist)
median(cars$dist)
```

Why do you think there is a discrepancy between the mean and the median?
What could be the advantage of using the median over then mean, in general?

## Standard deviation

```{r}
sd(cars$dist)
sd(cars$dist)
```

### EXERCISE 4

We can also simulate distributions:

```{r}
?rnorm # rnorm allows us to generate values from a normal distribution

dist <- data.frame(sample = rnorm(1000, mean = 0, sd = 1))
ggplot(dist, aes(x = sample)) +
  geom_density()
```

Plot samples from a normal variable with sd = 2 and sd = 3. Can you make the lines different colours?

```{r}
# ANSWER HERE
```

What aspect of the distribution does the standard deviation control?

## Skewness

```{r}
install.packages('moments')
library(moments)
```

```{r}
skewness(cars$speed)
skewness(cars$dist)
```

What do you think the skewness is measuring?

## Boxplot

We can visualise the distribution of variables using a "Box and Whisker plot", or "Boxplot". 

This requires us to reformat the data:

```{r}
library(tidyverse) # tidyverse has lots of useful tools and syntax for dealing with datasets
cars %>% # %>% is the pipe operator, it tells the following function to use this dataframe as the input
  pivot_longer(cols = c(dist, speed))
```

What does `pivot_longer` do?

```{r}
cars %>%
  pivot_longer(cols = c(speed, dist)) -> long
# See? -> is useful : )
```

Now to make the boxplot:

```{r}
ggplot(long, aes(x = name, y = value)) +
  geom_boxplot()
```

How could we improve this boxplot?

We can add panels to the plots:

```{r}
ggplot(long, aes(y = value)) +
  geom_boxplot() +
  facet_wrap(~name, scales = "free_y")
```

What happens when we remove `scales = 'free_y'`?

### EXERCISE 5

What is the key information displayed by the boxplot?

What are some limitations of the boxplot?

## Violin plot

### EXERCISE 6

Create a violin plot for the variables in the datasets and comment on the distributions.

```{r}
?geom_violin
```
 
# Probability and Distributions

There are several useful functions when dealing with probability distributions.

As a reminder, here are some common probability distributions:

- *Binomial-* The number of successes occurring for a fixed number of trials. For example, the number of heads when a coin is flipped $n$ times.
- *Poisson-* The number of events occurring in a fixed time interval. For example, the calls received by a call center in 1 hour.
- *Normal-* A continuous variable which is symmetric.

## Cumulative mass/density function

The *cumulative mass/density function** gives the probability that a random variable will be less than or equal to a particular value.

For example, 

```{r}
?pbinom
pbinom(3, size = 10, prob = 0.3)
```
gives the probability of seeing at most 3 heads if we have 10 biased coin flips, with a probability 0.3 of landing a heads each time.

```{r}
pnorm(3, mean = 0, sd = 1)
```
gives the probability that random variable with a normal distribution with mean 0 and sd 1 will be at most 3.

# EXERCISE 7

Suppose that around a particular time of day, an average of 6 cars pass a particular part of the road every minute. You can assume that this rate is constant.

What is the probability that less than 4 cars pass the junction in one minute?

```{r}
# ANSWER HERE
```

What is the probability that between 6 and 8 cars inclusive pass the junction in one minute?

```{r}
# ANSWER HERE
```

## Probability mass/density function (PMF, PDF)

The *probability mass/density function** gives the probability (for a discrete distribution) or the probability density (for a continuous distribution) for a particular value that the random variable can take.

For example, 
```{r}
dbinom(3, size = 10, prob = 0.3)
?pbinom
```
gives the probability of seeing 3 heads if we have 10 biased coin flips, with a probability 0.3 of landing a heads each time.

```{r}
dnorm(3, mean = 0, sd = 1)
```
gives the probability density for a normal distribution with mean 0 and sd 1 at 3.

### EXERCISE 7

What is the probability that a normally distributed variable with mean 0 and sd 1 is equal to 0.5?

```{r}
# ANSWER HERE
```

Can you think of any practical applications in Biostatistics for the PMF/PDF and CMF/CDF?

# Quantile function

The *quantile function* gives the smallest value below which the random variable takes with a probability at least $p$. (Yes this is a bit confusing describing without mathematics... but we will provide examples!!!)

For example, a normally distributed variable with mean 0 and sd 1 will take a value less than 
```{r}
qnorm(0.95)
```
is 0.95.

A binomially distributed variable with size 10, probability 0.3 of success will take a value less than or equal to 
```{r}
qbinom(0.1, size = 10, prob = 0.3)
```
**at least** 0.1 of the time. Note that 
```{r}
pbinom(1, size = 10, prob = 0.3)
```
so, it is not that it is less than 1 with a probability of exactly 0.1, but is the smallest value that the variable is less than with probability *at least* 0.1.

So we can think of the quantile function as a kind of pseudo-inverse function for the cumulative distribution function.

### EXERCISE 8

Moles are known to be the sites of melanoma development, so it is important to assess moles to determine if they might be cancerous.

A dermatologist is studying mole width as an indicator of melanoma. In healthy patients, mole widths are normally distributed with a mean of 6.0 mm, and the standard deviation of the sample mean from 10 moles is 0.2 mm.

The dermatologist suspects that a particular patient's moles may be unusually large, which could indicate melanoma.

If the mean width of a sample of 10 moles is measured, what is the minimum sample mean that would allow the dermatologist to be at least 95% confident that the mole widths are abnormally largeâ€”suggesting the presence of melanoma?

```{r}
# ANSWER HERE
```

Why do you think the quantile function is an exact inverse for continuous random variables but not for descrete random variables?

## Sample generation

Finally, we can also generate random samples

For example,
```{r}
rbinom(5, size = 10, prob = 0.3)
```
produces 5 samples from the binomial distribution.

### EXERCISE 9

Take 1000 samples from the binomial distribution with size 100, probability 0.3 of success.
Take 1000 samples from the normal distribution with mean 30, sd 4.58.
Select a method to visualise the distribution of the samples. What do you notice?

```{r}
# ANSWER HERE
```

What do you notice?

What do you think could be useful applications of drawing samples from a random variable?

## Statistical Hypothesis Testing

Statistical hypothesis tests are helpful tools to determine if there is sufficient evidence based on the data collected to update our beliefs about a population.

Typically this is done by:

1. **Making a statistical hypothesis.** This is a statement about the underlying distribution of random variable. For example, the mean length of a mole is 6.0mm.

2. **Calculating the test statistic.** The test statistic is a numerical summary of the data that we can compare to our distributional assumptions.

3. a) **Calculating the p-value.** We then calculate the probability of the test statistic occurring under our assumptions. If it is sufficiently low, this is interpreted as evidence that our starting hypothesis was not correct.

3. b) **Calculating the critical value.** We can also calculate a threshold value for the test statistic. If the test statistic is beyond this threshold, the critical value, then this is evidence that our starting hypothesis was not correct.

### EXERCISE 10

We are now going to attempt a simple hypothesis test to determine if a certain coin is fair or not...!

You flip the coin 20 times, and it comes up heads 13 times.

*Making the hypothesis.* We can assume that the coin is innocent... until proven guilty! What should we state as our **null hypothesis** ($H_0$), i.e. our starting hypothesis and our **alternative hypothesis** ($H_1$).

$H_0$: YOUR ANSWER HERE
$H_1$: YOUR ANSWER HERE

*Test statistic.* In this case we can use 13, the number of heads, as the test statistic.

*p-value method.* What is the probability under the null hypothesis $H_0$ that the coin would produce 13 heads?

```{r}
# YOUR ANSWER HERE
```

*Critical value method.* Suppose we would only conclude that the coin is unfair if there was less than a 5% chance that we would observe the test statistic under the null hypothesis $H_0$. The probability threshold we refer to here is known as the **significance level**. What would be the minimum value that would cause us to reject $H_0$?

```{r}
# YOUR ANSWER HERE
```

In this case would we accept or reject $H_0$?

Suppose you need to communicate your finding to the coin manufacturer. Can you summarise the result of the statistical test?

Which method do you prefer, p-value method, or critical value method?

Suppose you are testing multiple coins for bias. What might be the problem with using this approach to determine if a coin is biased?

## Error types

Unfortunately, hypothesis tests can only give us a principled way of updating our beliefs. There is always a chance we can arrive at the wrong conclusion.

**Type I Error-** We reject a true null hypothesis.

**Type II Error-** We accept a false null hypothesis.

### EXERCISE 11

Back to the dermatology clinic...

(To reiterate:) In healthy patients, mole widths are normally distributed with a mean of 6.0 mm, and the standard deviation of the sample mean from 10 moles is 0.2 mm. Suppose that in a particular patient, their mole width is normally distributed with a mean of 5.0 mm instead.

Let us adopt a 5% significance level. What would. be the type I and II errors when testing for melanoma in this case?

```{r}
# YOUR ANSWER HERE
```

What kind of problems could each type of error cause to the patient, and what would your suggestion be to improve the test based on your calculation?

# Correlation and Regression
Troubleshooting...

The code is looking for files in the working directory (wd):

```{r}
getwd() # get the working directory
```

If you can't load the file, check it is in the right location!